{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "HexGridGeneratorNew.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "Q90GJqVlLpe0",
        "yUhA1lfGQYKW"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nsp8/HexGridGenerator/blob/master/HexGridGeneratorNew.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iWvMNXWH9UW-",
        "colab_type": "text"
      },
      "source": [
        "# HexGrid Generator\n",
        "## Create hexagonal maps representing countries of the world by reading files from your Google Drive\n",
        "\n",
        "---\n",
        "Note: In your Google Drive, under ***My Drive***, create a folder **World HexGrid** and in that - an ***Input*** and an ***Output*** folder. Store all your files that need to be processed in the ***Input*** folder."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m6Tgcvss_BWW",
        "colab_type": "text"
      },
      "source": [
        "### Install all the required packages"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_zGoah_kBFgs",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LEpEaSoiJWan",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install geojson geopandas"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "chCyzfVB_HnS",
        "colab_type": "text"
      },
      "source": [
        "### Enable Matplotlib visualizations in this notebook"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pYEWQzCc-8_m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WS0p8LSQ_Ppv",
        "colab_type": "text"
      },
      "source": [
        "### Import the packages needed to process and create HexGrid maps"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MmiBIoOeCSec",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from functools import reduce\n",
        "from google.colab import drive\n",
        "from numpy import nan\n",
        "import geojson\n",
        "import geopandas as gpd\n",
        "import json\n",
        "import math\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import pandas as pd\n",
        "import re"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZQ2eMLOXLZR2",
        "colab_type": "text"
      },
      "source": [
        "### Initialize the global variables - input and output directories\n",
        "---\n",
        "*Note: these directories must be in your Google Drive*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KXBolRJVLYl-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "input_directory = '/gdrive/My Drive/World HexGrid/Input/'\n",
        "output_directory = '/gdrive/My Drive/World HexGrid/Output/'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qWyASVKLACNO",
        "colab_type": "text"
      },
      "source": [
        "## All the functions that process, clean, format, and visualize your data are defined below:\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tXG7zqORATGl",
        "colab_type": "text"
      },
      "source": [
        "### get_regular_hex_coords\n",
        "returns the coordinates of the hexagon around ***x*** and ***y***."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5wWouSxsEw5M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_regular_hex_coords(x, y):\n",
        "    r = 1 / math.sin(math.pi/3)\n",
        "    coords_ = list()\n",
        "    n = 6\n",
        "    base_angle = 360 // n\n",
        "    for i in range(n):\n",
        "        relative_angle = ((base_angle * i) + (base_angle // 2)) * (math.pi / 180)\n",
        "        coord_ = [x + (r * math.cos(relative_angle)), y + (r * math.sin(relative_angle))]\n",
        "        coords_.append(coord_)\n",
        "    coords_.append(coords_[0])\n",
        "    return coords_"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A3Hfm_arBCHM",
        "colab_type": "text"
      },
      "source": [
        "### create_hex_grid\n",
        "returns GeoJSON data (```FeatureCollection```) of the input ***DataFrame*** that contains geographical and statistical data of the countries."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TS4ovhrYJh1z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_hex_grid(dataframe):\n",
        "    world_hex = geojson.FeatureCollection(features=[])\n",
        "    i = 0\n",
        "    countries = dataframe[\"id\"]\n",
        "    for country in list(countries):\n",
        "        params = (dataframe[countries == country].to_dict('records'))[0]\n",
        "        hex_coords = get_regular_hex_coords(params[\"x\"], params[\"y\"])\n",
        "        country_hexagon = geojson.Polygon([hex_coords])\n",
        "        country_feature = geojson.Feature(geometry=country_hexagon, \n",
        "                                          properties=params)\n",
        "        world_hex[\"features\"].append(country_feature)\n",
        "        i += 1\n",
        "    return world_hex\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ek1WBnuNBrDy",
        "colab_type": "text"
      },
      "source": [
        "### save_geojson\n",
        "saves the GeoJSON object in the Google Drive ***Output*** folder; returns the total path of the stored file, if it was saved successfully, or **```None```** otherwise."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-ilHxYAqKq0v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def save_geojson(geojson_obj, filename):\n",
        "    out_file = os.path.join(output_directory, filename)\n",
        "    with open(out_file, \"w\") as output:\n",
        "        json.dump(geojson_obj, output, indent=4)\n",
        "    if os.path.lexists(out_file):\n",
        "        return out_file\n",
        "    return None"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RXyx2YGbIka4",
        "colab_type": "text"
      },
      "source": [
        "### check_iso_values\n",
        "returns the name of the column whose values are consistent with ISO2 format in **```data_df```**."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ORa3rBbARvLX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def check_iso_values(data_df):\n",
        "    # col_map = {}\n",
        "    for col in data_df.columns:\n",
        "        values = list(data_df[col])\n",
        "        string_bool = [is_str for is_str in map(\n",
        "            lambda x: len(x) == 2 if (type(x) == str) else False, values)]\n",
        "        all_string = reduce(lambda x, y: x & y, string_bool)\n",
        "        # col_map[col] = [string_bool.index(b) for b in string_bool if not b]\n",
        "        if all_string:\n",
        "            return col\n",
        "    # print(col_map)\n",
        "    print(\"Processed all columns but no match found\")\n",
        "    return None\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t3FktX82D8Qf",
        "colab_type": "text"
      },
      "source": [
        "### remove_spaced_columns\n",
        "returns a new dataframe with updated column names, if they contain spaces in **```df```**."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YPOoAYdY6PG7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def remove_spaced_columns(df):\n",
        "    new_cols = dict()\n",
        "    for col in df.columns:\n",
        "        if len(col) > len(col.strip()):\n",
        "            # print(\"{} has to be corrected\".format(col))\n",
        "            new_cols.update({col: col.strip()})\n",
        "    if new_cols:\n",
        "        return df.rename(columns=new_cols)\n",
        "    else:\n",
        "        return df"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9vsY8zIBC0Cr",
        "colab_type": "text"
      },
      "source": [
        "### handle_excel_data\n",
        "returns a single dataframe of the values from all the sheets of the Excel workbook (**```excel_collection```**) -  combined on the basis of the ***country codes (ISO2)***."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZIwT96VuJBEN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def handle_excel_data(excel_collection):\n",
        "    new_df = pd.DataFrame()\n",
        "    prev_sheet = ''\n",
        "    for sheet_name, inputs_df in excel_collection.items():\n",
        "        inputs_df = remove_spaced_columns(inputs_df)\n",
        "        inputs_df.replace(r'^\\s*$', nan, regex=True, inplace=True)\n",
        "        inputs_df.replace(r'[-–]+$', nan, regex=True, inplace=True)\n",
        "        inputs_df.replace(r',', '', regex=True, inplace=True)\n",
        "        inputs_df.dropna(subset=inputs_df.columns[1:], how='all', inplace=True)\n",
        "        inputs_df.dropna(axis=1, how=\"all\", inplace=True)\n",
        "        if new_df.empty:\n",
        "            new_df = inputs_df\n",
        "            prev_sheet = sheet_name\n",
        "            iso_col = check_iso_values(new_df)\n",
        "            if iso_col:\n",
        "                new_df.set_index(iso_col, inplace=True)\n",
        "        else:\n",
        "            iso_col = check_iso_values(inputs_df)\n",
        "            if iso_col:\n",
        "                inputs_df_n = inputs_df.set_index(iso_col)\n",
        "                new_df = new_df.join(inputs_df_n, \n",
        "                                     how=\"inner\",\n",
        "                                     lsuffix='_{}'.format(prev_sheet),\n",
        "                                     rsuffix='_{}'.format(sheet_name))\n",
        "    return new_df"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x_IWbLLKsYaa",
        "colab_type": "text"
      },
      "source": [
        "### handle_csv_data\n",
        "returns a single dataframe of the values from all the sheets of the CSV file (**```data_file```**) -  combined on the basis of the ***country codes (ISO2)***."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SqACo585POQx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def handle_csv_data(data_file, skip=0):\n",
        "    encodings = [\"utf-8\", \"cp1252\", \"ISO-8859-1\"]\n",
        "    data_df = pd.DataFrame()\n",
        "    for encoding in encodings:\n",
        "        # to handle UnicodeDecodeError\n",
        "        try:\n",
        "            if skip:\n",
        "                data_df = pd.read_csv(data_file, \n",
        "                                      encoding=encoding,\n",
        "                                      keep_default_na=False,\n",
        "                                      skiprows=list(range(skip)))\n",
        "            else:\n",
        "                data_df = pd.read_csv(data_file,\n",
        "                                      keep_default_na=False,\n",
        "                                      encoding=encoding)\n",
        "            break\n",
        "        except UnicodeDecodeError as e:\n",
        "            print(\"Encoding format '{}' didn't work\".format(encoding))\n",
        "            print(\"Trying the next encoding...\\n\")\n",
        "            continue\n",
        "    print(\"File read successfully\")\n",
        "    data_df.replace(r'^\\s*$', nan, regex=True, inplace=True)\n",
        "    data_df.replace(r'[-–]+$', nan, regex=True, inplace=True)\n",
        "    data_df.replace(r',', '', regex=True, inplace=True)\n",
        "    data_df.dropna(axis=0, how=\"all\", subset=data_df.columns[1:], inplace=True)\n",
        "    data_df.dropna(axis=1, how=\"all\", inplace=True)\n",
        "    data_df = remove_spaced_columns(data_df)\n",
        "    return data_df\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kSKzaD_ltQBY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "encodings = [\"utf-8\", \"cp1252\", \"ISO-8859-1\"]\n",
        "data_df = pd.DataFrame()\n",
        "for encoding in encodings:\n",
        "    # to handle UnicodeDecodeError\n",
        "    try:\n",
        "        if skip:\n",
        "            data_df = pd.read_csv(data_file, \n",
        "                                    encoding=encoding,\n",
        "                                    keep_default_na=False,\n",
        "                                    skiprows=list(range(skip)))\n",
        "        else:\n",
        "            data_df = pd.read_csv(data_file,\n",
        "                                    keep_default_na=False,\n",
        "                                    encoding=encoding)\n",
        "        break\n",
        "    except UnicodeDecodeError as e:\n",
        "        print(\"Encoding format '{}' didn't work\".format(encoding))\n",
        "        print(\"Trying the next encoding...\\n\")\n",
        "        continue"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v9rrk2arEY2R",
        "colab_type": "text"
      },
      "source": [
        "### get_data_df\n",
        "returns ***DataFrame*** of the files selected (**```file_name```**) from ***Input*** folder."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ObgH8XudKgdF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_data_df(file_name):\n",
        "    data_file = os.path.join(input_directory, \"Data\", file_name)\n",
        "    data_df = pd.DataFrame()\n",
        "    if os.path.lexists(data_file):\n",
        "        if os.path.isfile(data_file):\n",
        "            file_ext = file_name.split(\".\")[-1]\n",
        "            \n",
        "            skip_msg = \"Do you want to skip any rows (excluding the header)?\"\n",
        "            skip_msg += \"\\nEnter: y or yes if the rows need to be skipped:\\n\"\n",
        "            if file_ext == \"csv\":\n",
        "                skip = input(skip_msg)\n",
        "                if skip and skip.lower() in [\"y\", \"yes\"]:\n",
        "                    skip_rows = int(input(\n",
        "                        \"Enter the number of rows you want to skip:\\n\"))\n",
        "                    data_df = handle_csv_data(data_file, skip=skip_rows)\n",
        "                else:\n",
        "                    data_df = handle_csv_data(data_file)\n",
        "                iso_col = check_iso_values(data_df)\n",
        "                if iso_col:\n",
        "                    data_df.set_index(iso_col, inplace=True)\n",
        "            elif file_ext in [\"xls\", \"xlsx\"]:\n",
        "                skip = input(\"Do you want to skip any rows? \\n\")\n",
        "                \n",
        "                if skip and skip.lower() in [\"y\", \"yes\"]:\n",
        "                    skip_rows = int(input(\n",
        "                        \"Enter the number of rows you want to skip:\\n\"))\n",
        "                    data_df = pd.read_excel(data_file,\n",
        "                                            encoding=\"utf-8\",\n",
        "                                            sheet_name=None,\n",
        "                                            keep_default_na=False,\n",
        "                                            skiprows=list(range(skip_rows)))\n",
        "                else:\n",
        "                    data_df = pd.read_excel(data_file,\n",
        "                                            encoding=\"utf-8\",\n",
        "                                            sheet_name=None,\n",
        "                                            keep_default_na=False)\n",
        "                data_df = handle_excel_data(data_df)\n",
        "            else:\n",
        "                print(\"Invalid File Extension. Please try again\")\n",
        "        else:\n",
        "            print(\"Input is not a file\")\n",
        "    else:\n",
        "        print(\"File doesnot exist!\")\n",
        "    return data_df"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W0vAawKBJcE_",
        "colab_type": "text"
      },
      "source": [
        "### prompt_column\n",
        "prompts the user for a column value in the **```dataframe```** to show in the grid."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zz565sAJ2NWL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def prompt_column(dataframe):\n",
        "    column = input(\n",
        "        \"Which one of these columns do you want to show?: \\n{}\\n\".format(\n",
        "        list(dataframe.columns)))\n",
        "    return column"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QapH0fLOJ38U",
        "colab_type": "text"
      },
      "source": [
        "### show_hexgrid, set_plot_properties\n",
        "reads the saved **```geofile```** from the ***Output*** folder and plots the HexGrid.\n",
        "**```show_hexgrid```** expects the following arguments: \n",
        "1. column name to show \n",
        "2. colour_palette values (described here: [Matplotlib Colormaps](https://matplotlib.org/users/colormaps.html))\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "quvQM3ce71A_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def set_plot_properties(ax):\n",
        "    ax.yaxis.get_major_formatter().set_useOffset(False)\n",
        "    ax.get_xaxis().set_visible(False)\n",
        "    ax.get_yaxis().set_visible(False)\n",
        "    ax.text(s='Hexmap', \n",
        "            x=-1.0, y=-3.5, verticalalignment='bottom', \n",
        "            horizontalalignment='left')\n",
        "\n",
        "\n",
        "def show_hexgrid(geo_file, color_palette=\"blues\", column=None, col_name=None):\n",
        "    if geo_file:\n",
        "        plt.rcParams.update({'font.size': 22})\n",
        "        plt.rcParams[\"axes.formatter.useoffset\"] = False\n",
        "        worldhex_df = gpd.read_file(geo_file)\n",
        "        column = None if column == \"geometry\" or column == '' else column\n",
        "        \n",
        "        ax = worldhex_df.plot(column=column, \n",
        "                              cmap=color_palette,\n",
        "                              linewidth=3,\n",
        "                              edgecolor='black',\n",
        "                              figsize=(24, 24))\n",
        "\n",
        "        for ix, row in worldhex_df.iterrows():\n",
        "            x, y = row[\"x\"], row[\"y\"]\n",
        "            ax.annotate(row['id'], xy=(x, y), \n",
        "                        horizontalalignment='center',\n",
        "                        verticalalignment='center')\n",
        "        if column:\n",
        "            fig = ax.get_figure()\n",
        "            cax = fig.add_axes([0.90, 0.62, 0.008, 0.15])\n",
        "            vmin, vmax = worldhex_df[column].min(), worldhex_df[column].max()\n",
        "            sm = plt.cm.ScalarMappable(cmap=color_palette, \n",
        "                                       norm=plt.Normalize(vmin=vmin, vmax=vmax))\n",
        "            sm._A = []\n",
        "            cbar = fig.colorbar(sm, cax=cax)\n",
        "            if col_name:\n",
        "                cbar.set_label(col_name, labelpad=25)\n",
        "            else:\n",
        "                cbar.set_label(column, labelpad=25)\n",
        "        plt.tight_layout()\n",
        "        set_plot_properties(ax)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q90GJqVlLpe0",
        "colab_type": "text"
      },
      "source": [
        "## Mount the Google Drive to use it in this Notebook\n",
        "---\n",
        "### *Requires Authentication*\n",
        "To allow Google Colab to access your Google Drive, follow the instructions given in the cell below:\n",
        "\n",
        "\n",
        "1.   Click on the link below which will ask you to select your Google account\n",
        "2.   Authenticate your account. You will be redirected to a screen with a security key\n",
        "3.   Copy the security key and paste it into the box in the cell below"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oA_YOwCuHEcM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "drive.mount('/gdrive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8VsVJQrcNhNj",
        "colab_type": "text"
      },
      "source": [
        "## Read the HexCodes file from ***Input*** folder\n",
        "---\n",
        "*Note: This cell expects this file to be in CSV format.*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pD3FZlTQDHbM",
        "colab_type": "code",
        "cellView": "both",
        "colab": {}
      },
      "source": [
        "hexcodes_list = os.listdir(os.path.join(input_directory, \"Hexcodes\"))\n",
        "hexcodes_filename = \"\"\n",
        "if hexcodes_list:\n",
        "    hexcodes_filename = input(\n",
        "        \"Enter the hexcodes file name - \\nOptions: {}\\n\".format(\n",
        "        hexcodes_list))\n",
        "    print(\"Reading {} ...\".format(hexcodes_filename))\n",
        "else:\n",
        "    print(\"No hexcode file present! \\nPlease upload a file in the Input folder and try again.\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tK3o-H6FFB25",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if not hexcodes_filename:\n",
        "    hexcodes_filename = \"hexcodes_expanded.csv\"\n",
        "hexcode_file = os.path.join(input_directory, \"Hexcodes\", hexcodes_filename)\n",
        "hexcodes = pd.read_csv(hexcode_file, encoding=\"UTF-8\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yUhA1lfGQYKW",
        "colab_type": "text"
      },
      "source": [
        "## Visualize the *HexCodes* file.\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "n8sEG4ciuSak",
        "colab": {}
      },
      "source": [
        "column = None\n",
        "world_hex = create_hex_grid(hexcodes)\n",
        "world_hex_path = save_geojson(world_hex, \"new_output.geojson\")\n",
        "show_hexgrid(world_hex_path, \"plasma\", column)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K5CXzTe5QngI",
        "colab_type": "text"
      },
      "source": [
        "## Enter the file name you want to combine with the HexCodes:\n",
        "---\n",
        "*Note: Don't include quotes in the file name.*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ajrNct7TbWwk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_files = os.listdir(os.path.join(input_directory, \"Data\"))\n",
        "data_file = \"\"\n",
        "if data_files:\n",
        "    data_file = input(\n",
        "        \"Enter the file name you want to combine - \\nOptions: {}\\n\".format(\n",
        "        data_files))\n",
        "    print(\"\\nReading {} ...\".format(data_file))\n",
        "else:\n",
        "    print(\"No data file to integrate! \\nPlease upload a file in the Input folder and try again.\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qk97Xr-7RG0z",
        "colab_type": "text"
      },
      "source": [
        "## Create a DataFrame from the selected file from Google Drive.\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KsN26hFCQEdS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_df = get_data_df(data_file)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pexGs8fjRRrt",
        "colab_type": "text"
      },
      "source": [
        "## Combine HexCodes with the input data file.\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uqf8Sre_LWfg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if not data_df.empty:\n",
        "    hexcode_df = hexcodes.set_index(\"id\")\n",
        "    combi_df = hexcode_df.join(data_df, how=\"inner\")\n",
        "    combi_df.reset_index(inplace=True)\n",
        "    combi_df.rename(columns={'index': 'id'}, inplace=True)\n",
        "    combi_df.dropna(how=\"all\", axis=1, inplace=True)\n",
        "    combi_df.fillna('', inplace=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ej0aEmSpR1ls",
        "colab_type": "text"
      },
      "source": [
        "## Clean the DataFrame\n",
        "---\n",
        "*gets rid of duplicates and empty columns.*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ACRUFEFgR0Gd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if not data_df.empty:\n",
        "    combi_new_df = combi_df.T.drop_duplicates().T"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gG7D0RN3r9Da",
        "colab_type": "text"
      },
      "source": [
        "## Read the name of the column required to display on the plot:\n",
        "---\n",
        "*Note: Don't include quotes in the column name.*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tal14xhj8jH6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if not data_df.empty:\n",
        "    column = prompt_column(combi_new_df)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4NhiHCLAhSev",
        "colab_type": "text"
      },
      "source": [
        "## Display name of this column:\n",
        "---\n",
        "*Enter the name to associate the column with, that'll be displayed on the chart*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bo6pnHUpiIMg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "column_display_name = None\n",
        "if column:\n",
        "    column_display_name = input(\"Enter the name to display on the chart:\\n\")\n",
        "    if not column_display_name:\n",
        "        column_display_name = column\n",
        "else:\n",
        "    print(\"No column was selected in the previous step.\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zc3ysFCWTdcN",
        "colab_type": "text"
      },
      "source": [
        "## Create a filtered data-set on the column defined above.\n",
        "---\n",
        "*Criteria: filters values of the column in the range of **x**.*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2uwzfbEbwBja",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def validate_min_max(min_val, max_val):\n",
        "    bools = [True, True]\n",
        "    try:\n",
        "        if not min_val.isalpha() and not max_val.isalpha():\n",
        "            if float(max_val) <= float(min_val):\n",
        "                print(\"\\nMinimum value can't be greater than the maximum value!\")\n",
        "                print(\"Assigning the default min-max values\")\n",
        "                bools = [False, False]\n",
        "    except ValueError:\n",
        "        bools = [False, False]\n",
        "    return bools\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F9D5d-bqwFjy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if not data_df.empty:\n",
        "    combi_new_df[column] = combi_new_df[column].replace(\n",
        "        r'^\\s*$', nan, regex=True).dropna()\n",
        "    combi_new_df[column] = combi_new_df[column].astype(\"float\")\n",
        "    x_min = input(\n",
        "        \"Enter the minimum value of the column '{}'\\n\".format(column))\n",
        "    x_max = input(\n",
        "        \"Enter the maximum value of the column '{}'\\n\".format(column))\n",
        "    col_min, col_max = (combi_new_df[column].min(), combi_new_df[column].max())\n",
        "    if (not x_min) or (x_min.isalpha()):\n",
        "        x_min = str(col_min)\n",
        "    if (not x_max) or (x_max.isalpha()):\n",
        "        x_max = str(col_max)\n",
        "    min_valid, max_valid = validate_min_max(x_min, x_max)\n",
        "    combi_x_min = float(col_min) if not min_valid else float(x_min)\n",
        "    combi_x_max = float(col_max) if not max_valid else float(x_max)\n",
        "    print(\"\\nMinimum value: {}\\nMaximum value: {}\".format(combi_x_min, \n",
        "                                                          combi_x_max))\n",
        "    filter_condition = combi_new_df[column].ge(combi_x_min) & \\\n",
        "                       combi_new_df[column].le(combi_x_max)\n",
        "    subset_df = combi_new_df[filter_condition]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pn9tdw4uUYRE",
        "colab_type": "text"
      },
      "source": [
        "## Read the colormap values:\n",
        "---\n",
        "All the colormaps are here: [Matplotlib Colormaps](https://matplotlib.org/users/colormaps.html)\n",
        "\n",
        "*Note: Don't include quotes in the colormap names.*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "TuMU4hCBU_fO",
        "colab": {}
      },
      "source": [
        "if not data_df.empty:\n",
        "    colormap = input(\n",
        "        \"Enter the file name you want to combine - \\nOptions: {}\\n\".format(\n",
        "        plt.colormaps()))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WmT_ng1kad2O",
        "colab_type": "text"
      },
      "source": [
        "## Create the visualization of the data:\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PfRuGeuyvrLm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if not data_df.empty:\n",
        "    if not subset_df.empty:\n",
        "        combi_hex = create_hex_grid(subset_df)\n",
        "        out_file = save_geojson(combi_hex, \"combi_hex.geojson\")\n",
        "        show_hexgrid(out_file, colormap, column, column_display_name)\n",
        "    else:\n",
        "        print(\"No data found in this range. Plotting for all values:\")\n",
        "        combi_hex = create_hex_grid(combi_new_df)\n",
        "        out_file = save_geojson(combi_hex, \"combi_hex.geojson\")\n",
        "        show_hexgrid(out_file, colormap, column, column_display_name)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}
